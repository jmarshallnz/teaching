---
title: "227.215 Biostats Lab 1"
author: "Jonathan Marshall"
graphics: yes
output:
  pdf_document: null
  html_document: default
---

## Introduction

In this lab we'll start looking at the linear model. The linear model forms the basis of much statistical analysis. It is the more general version of simple linear regression, and encompases regression, analysis of variance and many other situations. We'll also be looking at some extensions to the general linear model, such as mixed effects models which have particular application where data have been collected across multiple paddocks, farms or regions.

## Exercise 1: Reminder - creating an R notebook from an R script

In this exercise we'll create a new R script, do some simple exploratory analysis, and then generate an R notebook from that.

1. Create a new R Script file to store the analysis we'll do today. To do this you can go to `File->New File->R Script` or alternatively click on the toolbar icon with the + on the left of it and select `R Script`.

2. Now type (or copy/paste) the following into the RScript file.

    ```{r, eval=FALSE}
    #' ## 227.215 Biostats
    
    #' In this notebook we'll take another look at data on Moroccan donkeys that we looked at
    #' in semester 1.
    donkey <- read.csv("http://www.massey.ac.nz/~jcmarsha/227215/data/donkey.csv")
    
    #' Take a look at it
    head(donkey)
    ```

3. You can highlight the code and click the `Run` button to execute it at any time. The code and output will go into the `Console` window.
4. Now we'll add a line to do a pairs plot of all the measurement variables on the donkeys.
    ```{r, eval=FALSE}
    #' A pairs plot of all measurement variables (columns 3 through 7)
    plot(donkey[,3:7])
    ```

5. Run that code to make sure you get the plot you want.
6. Now we'll produce an R notebook. Click on the little spiral-bound notebook on the toolbar (it will say `Compile Notebook` when you hover over it). It will prompt you to first save your R script - call it something like `donkey.R`. Once done, select `HTML` as the type of notebook to compile. It will do it's thing, and produce an HTML document.

## Exercise 2: The linear model

In this exercise we'll look at modelling the donkey `Bodywt` using the `Heartgirth`, like we saw in the first lecture. You should be able to see from your plot that this was the best variable to use for modelling the `Bodywt`.

1. Change the line of code in your R script to just generate a scatterplot of `Bodywt` versus `Heartgirth`. To jog your memory, try
    ```{r, eval=FALSE}
    plot(Bodywt ~ Heartgirth, data=donkey)
    ```
      
2. Notice it is an increasing relationship, and is reasonably linear. We'll try and fit a straight line to these data. i.e. we'll try and fit a relationship that takes the form
  $$
  \mathsf{BodyWt} = a + b \times \mathsf{Heartgirth}
  $$
where $a$ is the **intercept**, and $b$ is the **slope** of the relationship. We need to figure out what $a$ and $b$ should be. We could do this by guessing using the graph (e.g. we could take a guess at $b$ by figuring out the rise over the run), but we've got a computer, so why not let it do it for us?  You can do this with the `lm` function, short for **linear model**. Try the following.
    ```{r, eval=FALSE}
    lm1 <- lm(Bodywt ~ Heartgirth, data=donkey)
    ```
    This gives you a linear model object. To see what it contains, type the name of it `lm1`.

3. You can get more information by using the `summary` command on the `lm1` object.

    Notice the summary command gives quite a lot of information. We'll go through some of it here.
    * We have two rows, one for the `Intercept`, and one labelled `Heartgirth` - this is the slope.
    * The `Estimate` column gives us the values of each of these parameters might be in the population.
    * The `Std. Error` column is a measure of how much out we might be in the estimation. The reason we have this is we have just a sample of donkeys - we haven't measured all possible Moroccan donkeys! So, just like a sample mean might be a bit out (and we use a confidence interval to estimate how much out we might be) the estimates of the intercept and slope might also be a bit out. The standard error is the standard deviation of those estimates. A 95% confidence interval for the slope would be:
$$
2.82 \pm 2 \times 0.071,
$$
just like the confidence interval for a mean.
    * The `t value` column is giving the number of standard deviations away from 0 the slope and intercept estimates are (i.e. $39.74 = 2.82883 / 0.07118$).
    * The `Pr(>|t|)` column is the P-values for each of these estimates. The null hypothesis being tested is whether the slope (or intercept) is zero.

4. Write down the equation that relates the Body weight to the Heartgirth as a comment in your R script.

5. Think about what the P-value for the slope means. What would be your conclusion for this? Write some notes about this into your R-script as comments (i.e. pre-fixed using hash-quote `#' `) If you're not sure, discuss with those around you, or with Jonathan or the tutors.

6. Think about what the $R^2$ value (at the bottom of the summary output) means for the relationship between body weight and heartgirth. Write some notes about this into your R-script as comments.

7. Suppose you wanted to predict the weight of a donkey. You measure the girth at the heart and find it is 110cm. What is your best guess as to the body weight?  *Hint: Use the equation to work this out.*

8. Let's re-do part 7 using R. We do this by creating a data frame with the data to predict on, and then use the `predict` function. Add the following to your R script
    ```{r, eval=FALSE}
    #' predict the weight of a donkey with heart girth 110cm
    new_data <- data.frame(Heartgirth=110)
    predict(lm1, new_data)
    ```
9. We can improve this prediction by taking into account how much variation we expect this prediction to have. The variation comes from two sources:
    * The potential error in the line itself (we have just a sample, so our slope and intercept contain some error).
    * The variation of individuals about the line (i.e. variation not explained by the model).

    We can account for either the first or both of these in our predictions. Try the following:
    ```
    predict(lm1, new_data, interval="confidence")
    predict(lm1, new_data, interval="prediction")
    ```
    The first accounts only for the error in the line itself. That is, it is a *confidence* interval for the **average** weight for all donkeys with heartgirth 110cm.  The second accounts for the error in the line plus the variation of individuals about the line. Thus, it gives a *prediction* interval for the weight of an **individual** donkey with heartgirth 110cm. This is the range we expect individuals to be in.

## Exercise 3: Model diagnostics

Recall that the assumptions of the linear model are Linearity, Independence, Normality and Equal variance, with Linearity being the most important. Today we'll be looking at Linearity and Equal variance, both of which can be assessed using a plot of the residuals versus the fitted value.

If linearity holds, we'd expect a plot of residuals vs fitted value to show no trend - the points should be scattered fairly constantly above and below the line - in particular we don't want to see a curve.

If equal variance holds, we'd expect the scatter of points around the trend to be constant as the fitted value changes. You want it to be relatively even, and in particular not increasing from left to right (i.e. not spreading out).

An example of a good plot (left) and bad plot (right) is shown below.

```{r, fig.width=6, fig.height=2.5, echo=FALSE, dev='tikz', fig.align='center'}
set.seed(2)
x <- rnorm(100)
y <- x + rnorm(100, sd=0.1)
y2 <- exp(x/3 + rnorm(100, sd=0.1))
par(mfrow=c(1,2), mar=c(4,4,2,2))
plot(lm(y ~ x), which=1, sub.caption="")
plot(lm(y2 ~ x), which=1, sub.caption="")
```

 You can see more examples using the interactive found here:
 
 [**http://it056230.massey.ac.nz:8080/apps/shiny/linearity**](http://it056230.massey.ac.nz:8080/apps/shiny/linearity)

Let's see how well our model for body weight does.

1. Try producing the diagnostic plot for the linear model you fit above using the following. The `which=1` below just tells RStudio to plot the first diagnostic plot which is the one we want.

    ```{r, eval=FALSE}
    #' Residual vs fitted plot
    plot(lm1, which=1)
    ```

2. Take a good look at the plot. Do you think linearity and equal variance hold? **add a comment to your R script about each assumption**

3. A transformation is one way to deal with the non-linearity of the model. Instead of modelling the body weight in terms of the heart girth directly, we could instead take log transforms of both body weight and heart girth to get rid of the curvature in the relationship.

    ```{r, eval=FALSE}
    #' Let's try modelling the log of body weight versus log heartgirth to see if we
    #' get a better model.
    lm2 <- lm(log(Bodywt) ~ log(Heartgirth), data=donkey)
    summary(lm2)
    ```

4. Add the necessary code to produce the residual vs fitted plot for this new model. How is the assumption of linearity now? What about equal variance? *remember to add comments to your R script so they appear in your Word document at the end*

5. Compare the summary output of the two models you have. Which do you think is better? Why?

6. In the last lab we produced confidence and prediction intervals for a donkey with heartgirth equal to 110cm. Re-do these using your model. Remember that you'll need to exponentiate the resulting intervals! (Why?)

7. How do these intervals compare with your previous ones? *Add some comments to your R script about this.*

## Exercise 4: Visualising the model.

One way to visualise a linear model fit is by using the `visreg` package.

You might first need to install this package using the `Packages` menu in the bottom right. Just click the install button and type in `visreg`, then install.

1. Once you've installed the `visreg` package, start by visualising our first model. As we only have a single variable in the model (Heart girth) we can just call `visreg` directly on the model object:

    ```{r, eval=FALSE}
    #' Visualise the model fit using the `visreg` package.
    library(visreg)
    visreg(lm1)
    ```

    You should see that the fit is pretty good within the mid-range of `Heartgirth` but isn't so good at either end, where most of the observations are above the line rather than scattered on either side, due to the curvature. *Add a comment to your R script about this*.

2. Now try visualising the second linear model. You should notice that the x-axis is on the normal scale (even though we applied a log transformation in the model formula) but the y-axis is on the log scale. Nonetheless, the model fit should be a bit better, and will be curved. Notice that we've used a **linear** model to fit a curved relationship. The key is that the linearity of the model is in terms of the coefficients (each term can contain only one $\beta$ as a multiplier, and terms must be added together) not in terms of the way $y$ and $x$ are related. You can apply any transformation you like to $x$ and $y$ as needed to fit the data.

3. You can visualise the second linear model on the natural body weight scale by applying a transformation in the `visreg` command. Try the following:

    ```{r, eval=FALSE}
    visreg(lm2, trans=exp, partial=TRUE)
    ```

    The `trans=exp` uses exponentiation to transform the outcome variable. The `partial=TRUE` means that residuals (and thus data values) are plotted as points as well. You may want to change the y-axis label by adding `ylab="Body weight (kg)"` to the above command.

    *Add some comments to your R script about the model fit and how well you think it does. Notice that the confidence
    bands at the ends are larger than in the middle. Why is this?*
