---
title: "Linear models 3"
author: "Jonathan Marshall"
date: ""
output: 
  ioslides_presentation: 
    highlight: tango
    widescreen: true
    css: jm.css
---

```{r setup, echo=FALSE}
library(knitr)
opts_chunk$set(dev.args=list(bg='transparent'), comment='', warning=FALSE)
col_points <- "#7f577492"
col_dark   <- "#5f4354"
```
## Learning outcomes

- Review interpretation of `summary` and `anova` tables.

- Interactions.

# Review

## Summary table

- Each row is **adjusted** for the other rows.

- The coefficients are thus the effect after adjusting for the others.

- The P-values are whether that effect is significant, after adjusting for the others.

## Summary table for factors

- Each P-value is testing whether that coefficient is zero or not.

- Factors with more than 2 levels get **multiple rows**, one for each comparison to the baseline.

- We want to know if the factor is important, which means testing that multiple coefficients
are zero at the same time.

- We must use an F-test for this, i.e. the `anova` table.

## ANOVA table

- Each row represents a covariate, regardless of whether it's numeric or a factor.

- Can thus be used to test significance of factors directly.

- Order makes a difference. Each row is adjusted for the ones above it (but not below it).

- Usually order isn't an issue, but if it is, it tells you something.

# Example: Petrels

## Example: Petrels

```{r, echo=FALSE, fig.width=9.5}
petrels <- read.csv("http://www.massey.ac.nz/~jcmarsha/227212/data/petrels.csv")
petrels$Area <- as.factor(petrels$Area)
petrels$Sex <- as.factor(petrels$Sex)
levels(petrels$Sex) <- c("Female", "Male")
par(mar=c(5,5,1,0), cex.axis=1.5, cex.lab=1.5)
plot(R.Wing.Lth ~ Area, data=petrels, ylab="Right wing length (cm)")
```

## Example: Petrels

```{r, echo=FALSE, fig.width=7, fig.align='center'}
par(mar=c(5,5,1,0), cex.axis=1.5, cex.lab=1.5)
plot(R.Wing.Lth ~ Sex, data=petrels, ylab="Right wing length (cm)", xlab="", las=1, horizontal=TRUE)
```

## Petrels: ANOVA table

```{r}
mod = lm(R.Wing.Lth ~ Sex + Area, data=petrels)
anova(mod)
```

## Petrels: ANOVA table

```{r}
mod = lm(R.Wing.Lth ~ Area + Sex, data=petrels)
anova(mod)
```

## Petrels: Summary table {.smaller}

```{r, echo=FALSE}
summary(mod)
co <- round(coef(mod),2)
```

## Petrels: Conclusion

- From ANOVA table, both `Area` and `Sex` are important to the right wing length.

- From summary table, we see that males have `r co["SexMale"]`cm larger right wing length than females **after accounting for differences between areas**.

```{r, echo=FALSE}
mf = tapply(petrels$R.Wing.Lth, petrels$Sex, mean, na.rm=TRUE)
mf = round(mf[2]-mf[1],2)
ar = tapply(petrels$R.Wing.Lth, petrels$Area, mean, na.rm=TRUE)
ar = round(ar[5]-ar[1],2)
```

- This doesn't mean that male birds have a `r co["SexMale"]`cm larger right wing length than females.

- In fact
    ```{r}
    tapply(petrels$R.Wing.Lth, petrels$Sex, mean, na.rm=TRUE)
    ```
    they're `r mf`cm larger across all areas.

## Petrels: Conclusion

- Similarly, birds in area 5 have `r co["Area5"]`cm larger right wing length than those in area 1 **after accounting for differences in sex**.

- Again,
    ```{r}
    tapply(petrels$R.Wing.Lth, petrels$Area, mean, na.rm=TRUE)
    ```
    they're `r ar`cm larger across both sexes.

## What about left wing length?

```{r, echo=FALSE, fig.align='center', fig.width=7, fig.height=5}
par(mar=c(4,4,0,1))
plot(R.Wing.Lth ~ L.Wing.Lth, data=petrels, ylab="Right wing length (cm)", xlab="Left wing length (cm)", col=col_points, pch=19)
```

## Adding in left wing length

```{r}
mod2 = lm(R.Wing.Lth ~ L.Wing.Lth + Sex + Area, data=petrels)
anova(mod2)
```

## Adding in left wing length{.smaller}

```{r, echo=FALSE}
summary(mod2)
co2 <- round(coef(mod2),2)
```

## Adding in left wing length

- From the ANOVA table, we see left wing length, sex and area are all still significant.

- From the summary table, however, we note that the direction of the effect of `Sex` has changed!

- It is now saying that males have `r -co2["SexMale"]`cm smaller right wing lengths than females.

- Again, we've **adjusted for the other covariates**.

- **WEIRD!**

## Left and right wing lengths

```{r, echo=FALSE, fig.align='center', fig.width=7, fig.height=5}
col = c("#FF00005F", "#0000ff5F")

zones = matrix(c(2,0,1,3), ncol=2, byrow=T)
layout(zones, widths=c(6,1), heights=c(1,6))

par(mar=c(4,4,0.5,0.5),cex=1.5)
plot(R.Wing.Lth ~ L.Wing.Lth, data=petrels, ylab="Right wing length (cm)", xlab="Left wing length (cm)", col=col[Sex], pch=19, asp=1)
legend("bottomright", legend=levels(petrels$Sex), fill=col, bty="n", cex=1)
lf=density(na.omit(petrels$L.Wing.Lth[petrels$Sex == "Female"]))
lm=density(na.omit(petrels$L.Wing.Lth[petrels$Sex == "Male"]))
rf=density(na.omit(petrels$R.Wing.Lth[petrels$Sex == "Female"]))
rm=density(na.omit(petrels$R.Wing.Lth[petrels$Sex == "Male"]))

par(mar=c(0,4,0,0.5))
plot(NULL, xlim=range(petrels$L.Wing.Lth, na.rm=TRUE), ylim=c(0,max(lf$y, lm$y)), axes=F, ann=FALSE)
lines(lm, col=col[2], lwd=2)
lines(lf, col=col[1], lwd=2)

par(mar=c(4,0,0.5,1))
plot(NULL, ylim=range(petrels$R.Wing.Lth, na.rm=TRUE), xlim=c(0,max(rf$y, rm$y)), axes=F, ann=FALSE)
lines(rm$y, rm$x, col=col[2], lwd=2)
lines(rf$y, rf$x, col=col[1], lwd=2)
```

## Left and right wing lengths

- In both left and right wing lengths, males are bigger.

- However, the difference is larger in the left wing lengths than the right.

- So after accounting for the left wing length (where we're incorporating that large difference in the sexes) we have to reduce the difference to get back down to the difference we see in the right wing lengths.

- The only way to do that is if the `Sex` coefficient is negative.

## Summary

- Always look at the `anova` table first, particularly if you have factors.

- Look at the `summary` table next, and interpret the estimated coefficients there for the significant variables from the `anova` table.

- If variables are not significant, then you can remove them and re-run the `anova` and `summary` tables.

- **But this depends on what question we're answering!**

# Interactions

## Interactions

- Our current models have been assuming that each effect is **additive**.

- e.g. the difference in the right wing length between the sexes is common across all areas, and similarly the
area effects are common for males and females.

- This is often not the case.

## Example: Hypothetical drugs

- Suppose we have some medical condition and we have a numerical measure describing how good/bad a patient is.

- Suppose further that we have two drugs A and B to treat that condition, and that we have the option of combining them.

- Then there are 4 possible treatments: No drugs, just drug A, just drug B, or both drugs.

- Our current linear models, would assume that we can add the effect of drug A and B together for the "both drugs" case.

## Example: Hypothetical drugs

The model equation would be
$$
\mathsf{mean}(y) = \alpha + \beta_A z_A + \beta_B z_B
$$
where $z_A$ and $z_B$ are indicators for whether drug A or B are included, giving

Treatment     Mean
------------  ----
Neither drug  $\mathsf{mean}(y)=\alpha$
Just drug A   $\mathsf{mean}(y)=\alpha + \beta_A$
Just drug B   $\mathsf{mean}(y)=\alpha + \beta_B$
Both drugs    $\mathsf{mean}(y)=\alpha + \beta_A + \beta_B$

## Example: Hypothetical drugs

- For the combined drugs treatment, we have $\mathsf{mean}(y)=\alpha + \beta_A + \beta_B$

- We're thus assuming that the individual benefit of each drug add together when combined.

- But, it might be that the combined effect of the drugs gives is smaller or larger than the sum of individual effects.

- We need a bit more flexibility in the model.

## Example: Hypothetical drugs

<iframe src="http://it056230.massey.ac.nz:8080/227215/shiny/twoway/" style="border: none"></iframe>

## Interactions: Hypothetical drugs

We add another indicator variable $z_{AB}$ which is 1 when both drugs are in use.
$$
\mathsf{mean}(y) = \alpha + \beta_A z_A + \beta_B z_B + \beta_{AB} z_{AB}
$$

*Mathematical aside: the new variable is the product of the existing ones, as $z_{AB}=1$ only if both $z_A=1$ and $z_B=1$. $z_{A} \times z_{B}$ has this property.*

The means for the neither drug or single drug treatments are still the same, as $z_{AB}=0$ in those cases. The mean in the both drugs treatment is the only one that changes to
$$
\mathsf{mean}(y) = \alpha + \beta_A + \beta_B + \beta_{AB}.
$$
Thus, $\beta_{AB}$ can be used to measure whether or not the effects of the two drugs are additive or not.

## Interactions: Hypothetical drugs

- $\beta_{AB}$ can be used to measure whether or not the effects of the two drugs are additive or not.

- An alternate way to think about it is that the effect of drug B may differ depending on whether the patient is already given drug A.

- e.g. the effect for drug B may be to increase the diagnostic measurement by 5 units in the absence of other treatment, but if the patient is on drug A as well, then the effect of drug B may be less pronounced.

## Example: Hypothetical drugs

<iframe src="http://it056230.massey.ac.nz:8080/227215/shiny/twoway/" style="border: none"></iframe>

## Interactions in RStudio

```{r}
mod3 = lm(R.Wing.Lth ~ Sex + Area + Sex:Area, data=petrels)
anova(mod3)
```
As the interaction here is between factors, it should be evaluated using the ANOVA table.

## Interactions in RStudio

```{r, echo=FALSE}
pval=round(anova(mod3)[,5],3)
names(pval)=rownames(anova(mod3))
```
- From the `anova` table we see the interaction term is not significant (P=`r pval["Sex:Area"]`).

- Thus, there is no evidence in the data to suggest that the comparative size of male and female petrels differ between areas.

## Summary table of interactions{.smaller}

```{r, echo=FALSE}
summary(mod3)
co3=round(coef(mod3),2)
```

## Summary table of interactions

- While the interaction term isn't significant (thus all the interaction coefficients could be zero in the population) let's assess what each row represents.

- The Intercept contains the first levels of each factor, so females in area 1 have on average `r co3["(Intercept)"]`cm right wing lengths.

- The `SexMale` term is the difference to the baseline, so this describes how males in area 1 differ. They have right wing lengths `r co3["SexMale"]`cm larger.

- The `Area2` term is the difference to the baseline, so this describes how females in area 2 differ from those in area 1. Their right wing lengths are `r -co3["Area2"]`cm smaller.

- The `SexMale:Area2` is the differential effect of males in area 2 over and above the `SexMale` and `Area2` effects. Compared with females in area 1, males in area 2 are $`r co3["SexMale"]`+`r co3["Area2"]`+`r co3["SexMale:Area2"]`=`r sum(co3[c("SexMale","Area2","SexMale:Area2")])`$cm larger.

## Visualising models using visreg

When you have interactions, visualise the effect of one variable within the levels of another.

Allows you to see how effects interact.

Better way to present results from the model than summary table.

```{r, echo=TRUE, eval=FALSE}
library(visreg)
visreg(mod3, "Area", by="Sex")
visreg(mod3, "Area", by="Sex", overlay=TRUE)
```

## visreg: Model without interaction

```{r, echo=FALSE, fig.width=9.5, fig.height=5.5}
library(visreg)
par(mar=c(4,4,0,0))
visreg(mod, "Area", by="Sex")
```

## visreg: Model with interaction

```{r, echo=FALSE, fig.width=9.5, fig.height=5.5}
library(visreg)
par(mar=c(4,4,0,0))
visreg(mod3, "Area", by="Sex")
```

## visreg: without interaction (`overlay=TRUE`)

```{r, echo=FALSE, fig.width=9.5, fig.height=5.5, warning=FALSE}
par(mar=c(4,4,1,0))
visreg(mod, "Area", by="Sex", overlay=TRUE)
```

## visreg: with interaction (`overlay=TRUE`)

```{r, echo=FALSE, fig.width=9.5, fig.height=5.5, warning=FALSE}
par(mar=c(4,4,1,0))
visreg(mod3, "Area", by="Sex", overlay=TRUE)
```

## Other types of interaction

Consider
$$
\mathsf{mean}(y) = \alpha + \beta_1 x + \beta_2 z
$$
where $x$ is a numeric variable and $z$ is an indicator variable for the 2nd level of a factor variable.

Then if we're in the first level of the factor variable, $z=0$ so the equation is
$$
\mathsf{mean}(y) = \alpha + \beta_1 x
$$
If we're in the second level, $z=1$ so that
$$
\mathsf{mean}(y) = \alpha + \beta_1 x + \beta_2 = (\alpha + \beta_2) + \beta_1 x.
$$

The model fit is thus two parallel lines, separated by $\beta_2$.

## Petrels: Left and right wing lengths

```{r, echo=FALSE}
mod4 = lm(R.Wing.Lth ~ L.Wing.Lth + Sex, data=petrels)
```
```{r, echo=TRUE, eval=FALSE}
visreg(mod4, "L.Wing.Lth", by="Sex", overlay=TRUE)
```

```{r, echo=FALSE, fig.align='center', fig.width=7, fig.height=5}
par(mar=c(4,4,1,1))
points.col = c("#0000ff1F", "#FF00001F")
lines.col = c("#0000FFFF", "#FF0000FF")
bands.col = c("#0000FF5F", "#FF00005F")
visreg(mod4, "L.Wing.Lth", by="Sex", overlay=TRUE, points.par=list(col=points.col, cex=1.2), line.par=list(col=lines.col), fill.par=list(col=bands.col))
```

## Interaction of numeric variables and factors

We could add another term using the product of the numeric variable $x$ and the indicator for the second level of the factor $z$
$$
\mathsf{mean}(y) = \alpha + \beta_1 x + \beta_2 z + \beta_3 (x z).
$$

Then if we're in the first level of the factor variable, $z=0$ so the equation is
$$
\mathsf{mean}(y) = \alpha + \beta_1 x
$$
whereas if we're in the second level, $z=1$ so that
$$
\mathsf{mean}(y) = \alpha + \beta_1 x + \beta_2 + \beta_3 x = (\alpha + \beta_2) + (\beta_1 + \beta_3) x.
$$
The model fit is thus two separate lines.

## Petrels: Left and right wing lengths

```{r}
mod5 = lm(R.Wing.Lth ~ L.Wing.Lth + Sex + L.Wing.Lth:Sex, data=petrels)
anova(mod5)
```

## Petrels: Left and right wing lengths{.smaller}

```{r}
summary(mod5)
```

## Petrels: `visreg` the interaction

```{r, echo=TRUE, eval=FALSE}
visreg(mod5, "L.Wing.Lth", by="Sex", overlay=TRUE)
```

```{r, echo=FALSE, fig.align='center', fig.width=7, fig.height=5}
par(mar=c(4,4,1,1))
points.col = c("#0000ff1F", "#FF00001F")
lines.col = c("#0000FFFF", "#FF0000FF")
bands.col = c("#0000FF5F", "#FF00005F")
visreg(mod5, "L.Wing.Lth", by="Sex", overlay=TRUE, points.par=list(col=points.col, cex=1.2), line.par=list(col=lines.col), fill.par=list(col=bands.col))
```

## Petrels: Points with large influence?

```{r, echo=FALSE, fig.align='center', fig.width=7, fig.height=5}
par(mar=c(4,4,1,1))
plot(mod5, which=5)
```

## Petrels: Points with large influence?

```{r}
mod5b = lm(R.Wing.Lth ~ L.Wing.Lth + Sex + L.Wing.Lth:Sex, data=petrels[-c(492,638),])
anova(mod5b)
```

<div align='center'>
**ALWAYS PLOT THE DATA**
</div>

## Determining the 'best' model

- The best model depends on what questions you want to answer.

- If the goal of the model is to use it for prediction purposes, then you don't want to include extra terms that aren't significant.

- However, if the goal of the model is to answer questions about which variables effect the outcome, a model containing insignficant terms may be appropriate.
